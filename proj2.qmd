```{r echo=FALSE}
suppressPackageStartupMessages({
library(factoextra)
library(tidyverse)
library(GGally)
library(caret)
library(lctools)
library(sqldf)
library(latex2exp)
library(tidymodels)
library(patchwork)
library(tree)
library(glmnet)
library(MASS)
library(xgboost)
library(pROC)
})

# importing CV master function 
source("CVmaster.R")
```

# 1)

## a) on overleaf

half page summary of paper

## b) summary of data

```{r cache=TRUE}
# loading data 
img1 = data.frame(read.table("image_data/imagem1.txt"))
img2 = data.frame(read.table("image_data/imagem2.txt"))
img3 = data.frame(read.table("image_data/imagem3.txt"))

# name the columns  
col_names = c("y", "x", "label", "NDAI", "SD", "CORR", "DF","CF","BF","AF","AN")
colnames(img1) = col_names
colnames(img2) = col_names
colnames(img3) = col_names

# add source column to split into other sets 
img1$source = "img1"
img2$source = "img2"
img3$source = "img3"

# manipulation to make plotting easier 
lab_combined = rbind(img1[,c("x", "y", "label","source")],
                     img2[,c("x", "y", "label","source")],
                     img3[,c("x", "y", "label","source")])

# change to factors to color when plotting 
lab_combined$label = as.factor(lab_combined$label)

# combining everything for later 
img_combined = rbind(img1,img2,img3)
```

Geographic plot and bar plot of labels

```{r}
ggplot(lab_combined, aes(x=x,y=y)) + 
  geom_point(aes(colour = label)) + 
  facet_grid(cols = vars(source)) + 
  labs(title = "Images With Expert Labels",
       subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  scale_colour_brewer("Expert \nLabel")

lab_combined2 = lab_combined %>%
  group_by(source, label) %>%
  count(label) %>%
  ungroup(label) %>%
  mutate(prop = n / sum(n))

ggplot(lab_combined2, aes(label,fill=label)) + 
  geom_col(aes(y = prop), col = "darkgrey") + 
  facet_grid(cols = vars(source)) + 
  labs(title = "Images With Expert Labels",
       subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  ylab("Proportion of Pixels") + 
  scale_fill_brewer("Expert \nLabel")
```

## c) EDA

For some basic EDA, I took a random sample of the total data to allow for quicker plotting. This should retain the structure of the data, but may remove some outliers.

```{r}
set.seed(1124)
eda_sample = sample_n(img_combined,10000)
```

PCA

```{r }
rand.pca = prcomp(eda_sample[,4:11], center=TRUE, scale = TRUE)
fviz_pca_biplot(rand.pca, geom="point", habillage = eda_sample$label)
```

Plotting some pairs

```{r}

# https://www.blopig.com/blog/2019/06/a-brief-introduction-to-ggpairs/
ggpairs(eda_sample, 
        columns=4:11, # all columns 
        ggplot2::aes(color=as.factor(label),alpha=0.2),
        progress = FALSE,
        lower = list(continuous = wrap("smooth", alpha = 0.3, size=0.3)))
```

Investigating the features. Below we removed the 0 labels, though they can be added back in if necessary.

```{r}
# =============================================================================
# Summarizing features here 
# =============================================================================

# summarizing NDAI 
eda_sample %>%
  filter(label != 0) %>%
  group_by(label) %>%
  summarize(meanndai = mean(NDAI),
            minndai = min(NDAI),
            maxndai = max(NDAI))

# summarizing SD 
eda_sample %>%
  filter(label != 0) %>%
  group_by(label) %>%
  summarize(meanSD = mean(SD),
            minSD = min(SD),
            maxSD = max(SD))

# summarizing CORR 
eda_sample %>%
  filter(label != 0) %>%
  group_by(label) %>%
  summarize(meanCORR = mean(CORR),
            minCORR = min(CORR),
            maxCORR = max(CORR))

# =============================================================================
# making plots of the features 
# TODO: add labels below? 
# =============================================================================

# plotting SD 
sd_plot = eda_sample %>%
  filter(label == 1) %>%
  ggplot(aes(x = log(SD))) +
  geom_density(fill = "lightblue", alpha = 0.8) + 
  geom_density(data = eda_sample %>% filter(label == -1), 
                 fill = "magenta", alpha = 0.4)

#density of NDAI
ndai_plot = eda_sample %>%
  filter(label == 1) %>%
  ggplot(aes(x = NDAI)) +
  labs(y = "") +
  geom_density(fill = "lightblue", alpha = 0.8) + 
  geom_density(data = eda_sample %>% filter(label == -1), 
               fill = "magenta", alpha = 0.4)

#density plot of CORR
corr_plot = eda_sample %>%
  filter(label == 1) %>%
  ggplot(aes(x = CORR)) +
  labs(y = "") +
  geom_density(aes(fill = "Cloud"), alpha = 0.8) + 
  geom_density(data = eda_sample %>% filter(label == -1), 
               aes(fill = "No Cloud"), alpha = 0.4) + 
  scale_fill_manual(name = "Expert Label", 
                     breaks = c("Cloud", "No Cloud"),
                     values = c("Cloud" = "lightblue",
                                "No Cloud" = "magenta"))

sd_plot + ndai_plot + corr_plot 
```

```{r}

p1 = eda_sample %>%
  filter(label != 0) %>%
  ggplot() +
  geom_point(aes(x = NDAI, y = CORR, col = as.factor(label))) + 
  theme(legend.position = "none")
  
p2 = eda_sample %>%
  filter(label != 0) %>%
  ggplot() +
  geom_point(aes(x = NDAI, y = SD, col = as.factor(label))) + 
  theme(legend.position = "none")

p3 = eda_sample %>%
  filter(label != 0) %>%
  ggplot() +
  geom_point(aes(x = SD, y = CORR, col = as.factor(label))) + 
  theme(legend.position = "bottom") + 
  labs(color = "Expert Label")
  

# combining plots with patchwork
p1 / p2 / p3 
```

#### analysis on the silly little angles

Notes on angular features: (re plot below) green is non-cloud, pink is cloud\] DF: very much overlap, -1 has most density in a smaller range than with 1 CF: upper values for -1, but vals still overlap BF: upper values for -1, but vals still overlap (maybe more extreme than with CF) AF: upper values for -1, but vals still overlap. -1 has a much much narrower range than 1 AN: upper values for -1, but vals still overlap. -1 has a much much narrower range than 1

```{r}
eda_sample %>%
  filter(label == 1) %>%
  #replace x = with feature of choosing
  ggplot(aes(x = BF, y = ..density..)) +
  geom_histogram(fill = 2, alpha = 0.5) + 
  geom_histogram(data = eda_sample %>% filter(label == -1), 
                 fill = 3, alpha = 0.5)
```

Boxplots:

```{r}

b1  = ggplot(eda_sample %>% filter(label != 0), aes(x=as.factor(label),y=AN, fill=label)) + 
  geom_boxplot(alpha=.7) + 
  theme(legend.position = "none") + 
  labs(title = "Labels vs. AN", 
       x = "-1: No Cloud | 1 : Cloud",
       y = TeX("$45^{\\circ}$ front angle, MISR"))

# maybe? 
b2 = ggplot(eda_sample %>% filter(label != 0), aes(x=as.factor(label),y=log(SD + 0.001), fill=label)) + 
  geom_boxplot(alpha=.7) + 
  theme(legend.position = "none") + 
  labs(title = "Labels vs. log(SD)", 
       x = "-1: No Cloud | 1 : Cloud",
       y = TeX("$45^{\\circ}$ front angle, MISR"))

# NDAI
# good predictor for -1 
b3 = ggplot(eda_sample %>% filter(label != 0), aes(x=as.factor(label),y=NDAI, fill=label)) + 
  geom_boxplot(alpha=.7) + 
  theme(legend.position = "none") + 
  labs(title = "Labels vs. NDAI", 
       x = "-1: No Cloud | 1 : Cloud",
       y = TeX("$45^{\\circ}$ front angle, MISR"))

# CORR 
# good predictor for 1 
b4 = ggplot(eda_sample %>% filter(label != 0), aes(x=as.factor(label),y=CORR, fill=label)) + 
  geom_boxplot(alpha=.7) + 
  theme(legend.position = "none") + 
  labs(title = "Labels vs. CORR", 
       x = "-1: No Cloud | 1 : Cloud",
       y = TeX("$45^{\\circ}$ front angle, MISR"))


(b1 + b2) / (b3 + b4) 
```

# 2) preparation

## a) data split

### 1)

The first, and most naive approach, would be to simply treat the three images as training, validation, and test data sets respectively. We know the data is not i.i.d, so it would be inappropriate to randomly sample points for our different sets.

### 2)

Second, since the data is correlated, we can hand-pick slices from each of the three images that result in the desired split, but in a way that retains the ordering. If we split each image into three chunks, we can then choose the first, middle, and last chunk for each of the desired sets and combine them. If, for some reason, there is some kind of feature or interesting detail present in the "position" of a slice of the data, hopefully this will allow us to capture it without overstating accuracy in training. To do this, we calculated the indices by hand.

Naive Approach

```{r}
# naive way 
naive_train = img1
naive_test = img2
naive_validate = img3

# hand splitting 
alt_train = data.frame(rbind(img1[23023:92089,],
                             img2[46093:115229,],
                             img3[1:69130,]))

alt_test = data.frame(rbind(img1[1:23022,],
                             img2[23047:46092,],
                             img3[92175:115217,]))

alt_validate = data.frame(rbind(img1[92090:115110,],
                             img2[1:23046,],
                             img3[69131:92174,]))
```

## b) baseline

```{r}
trivial_naive.test = rep(-1,length(naive_test$label))
trivial_naive.validate = rep(-1,length(naive_validate$label)) 
trivial_alt.test = rep(-1,length(alt_test$label))
trivial_alt.validate = rep(-1,length(alt_validate$label))

naive_test_triv = mean(trivial_naive.test == naive_test$label)
naive_validate_triv = mean(trivial_naive.validate == naive_validate$label)

alt_test_triv = mean(trivial_alt.test == alt_test$label) 
alt_validate_triv = mean(trivial_alt.validate == alt_validate$label) 

1- naive_test_triv
1- naive_validate_triv
1- alt_test_triv
1- alt_validate_triv
```

## c) best features

## d) CV function - separate R file

```{r}
# a different loss example 
log_loss = function(y,y.pred) { 
  
  # y is label in train data 
  # y.pred = [0,1] probability 
  
  L = sum(-y * log(y.pred) - (1-y) * log(1-y.pred))
  return(L)
}


# classification loss function 
classification_error = function(y,y.pred){
  L = 1 - mean(y==y.pred)
  return(L)
}
```

```{r}
# function to merge and output basic stats 

custom_merge = function(df1,df2) {
  
  # combine data frames and calculate difference
  total = merge(df1,df2, by="k")
  colnames(total) = c("k","Val Method 1", "Val Method 2")
  total = total |> mutate(percent_diff = (total[,3] - total[,2])/total[,2] * 100)
  print(as_tibble(total))
  
  # maybe plot here 
  a = summary(total)
  return(a)
}
```

# 3) modeling

## a) fitting

Here, merging training and validation data:

```{r}

# method 1 
total = rbind(naive_train, naive_validate)

# all features from train and validate 
# for first validation method 
merge_m1_all = total |> 
  filter(label != 0) |> 
  mutate(label = as.factor(label))

# selected features 
merge_m1 = merge_m1_all |> 
  dplyr::select(label, NDAI, SD, CORR) 

# splitting into features and labels 
# possibly remove this 
merge_m1_feat = merge_m1 |> dplyr::select(NDAI,SD,CORR)
merge_m1_lab = merge_m1 |> dplyr::select(label)

# method 2 
total.alt = rbind(alt_train, alt_validate)

# all features from train and validate sets 
# from second method 
merge_m2_all = total.alt

# all features again but no zeros 
merge_m2_all = merge_m2_all |> 
  filter(label != 0) |> 
  mutate(label = as.factor(label))

# selected features 
merge_m2 = merge_m2_all |> 
  dplyr::select(label, NDAI, SD, CORR) 

# splitting features and labels 
# may not need later
merge_m2_feat = merge_m2 |> dplyr::select(NDAI,SD,CORR)
merge_m2_lab = merge_m2 |> dplyr::select(label)
```

Logistic Regression

```{r cache=TRUE}

# Standard Logistic Regression 

#NAIVE
fit1.log = glm(label ~ .,
           data = merge_m1, 
           family='binomial')

#ALTERNATE
fit2.log = glm(label ~ .,
           data = merge_m2, 
           family='binomial')

# CV  
# fit with first split method 
# must input data frame for glm 
cv.log1 = CVmaster(classifier = fit1.log,
                   train_feat = data.frame(merge_m1_feat), 
                   train_labels = merge_m1_lab,
                   folds= 10,
                   loss = classification_error)

# fit with second split method 
cv.log2 = CVmaster(classifier = fit2.log,
                   train_feat = data.frame(merge_m2_feat), 
                   train_labels = merge_m2_lab,
                   folds= 10,
                   loss = classification_error)

custom_merge(cv.log1,cv.log2)
```

### TEST LOG REGRESSION

```{r}
# method 1 
log_pred1 = predict(fit1.log, 
            naive_test[,c(4,5,6)],
            type='response')

pred_labels1 = rep(-1, length(log_pred1))
pred_labels1[log_pred1 > 0.5] = 1

naive_error1 = 1 - mean(pred_labels1 == naive_test$label)

# method 2 
log_pred2 = predict(fit2.log, 
            alt_test[,c(4,5,6)],
            type='response')

pred_labels2 = rep(-1, length(log_pred2))
pred_labels2[log_pred2 > 0.5] = 1

error2 = 1 - mean(pred_labels2 == alt_test$label)

cat("method 1: ", naive_error1,"\n", "method 2: ", error2)
```

Logistic Regression w L1 penalty

```{r cache=TRUE}

# Logistic Regression with L1 Penalty 


set.seed(123) 

#NAIVE
# cross validate to chooose best lambda 
cv1.l1 = cv.glmnet(as.matrix(merge_m1_all[,4:11]), #removing label
                   merge_m1_all[,3], # just label for x, y glmnet args
                   family = "binomial", 
                   alpha = 1)

log.l1.fit1 = glmnet(as.matrix(merge_m1_all[,4:11]), #removing label
                   merge_m1_all[,3], # just label for x, y glmnet args
                   family = "binomial", 
                   alpha = 1,
                   lambda = cv1.l1$lambda.min)

#BLOCK
# cross validate to chooose best lambda 
cv2.l1 = cv.glmnet(as.matrix(merge_m2_all[,4:11]), #removing label
                   merge_m2_all[,3], # just label for x, y glmnet args
                   family = "binomial", 
                   alpha = 1)

log.l1.fit2 = glmnet(as.matrix(merge_m2_all[,4:11]), #removing label
                   merge_m2_all[,3], # just label for x, y glmnet args
                   family = "binomial", 
                   alpha = 1, 
                   lambda = cv2.l1$lambda.min)

# CV  
# fit with first split method 
cv1.log.l1 = CVmaster(classifier = log.l1.fit1,
                   train_feat = as.matrix(merge_m1_all[,4:11]),
                   train_labels = merge_m1_lab,
                   folds= 10,
                   loss = classification_error)

cv2.log.l1 = CVmaster(classifier = log.l1.fit2,
                   train_feat = as.matrix(merge_m2_all[,4:11]),
                   train_labels = merge_m1_lab,
                   folds= 10,
                   loss = classification_error)

custom_merge(cv1.log.l1, cv2.log.l1)
```

```{r}
log.l1.fit1$beta
log.l1.fit2$beta
```

#### TEST LOGISTIC WITH L1 PENALTY

```{r}
# method 1 
log_l1_pred1 = predict(log.l1.fit1, 
                  as.matrix(naive_test[,4:11]),
                  type='response')

pred_labels1_l1 = rep(-1, length(log_l1_pred1))
pred_labels1_l1[log_l1_pred1 > 0.5] = 1

naive_error1_l1 = 1 - mean(pred_labels1_l1 == naive_test$label)

# method 2 
log_l1_pred2 = predict(log.l1.fit2, 
                  as.matrix(alt_test[,4:11]),
                  type='response')

pred_labels1_l2 = rep(-1, length(log_l1_pred2))
pred_labels1_l2[log_l1_pred2 > 0.5] = 1

alt_error1_l2 = 1 - mean(pred_labels1_l2 == alt_test$label)

cat("method 1: ", naive_error1_l1, "\n", "method 2: ", alt_error1_l2)
```

QDA / LDA

```{r}

#NAIVE WAY
qda.fit1 = qda(label ~ ., data = merge_m1)

# CV 
cv.qda1 = CVmaster(classifier = qda.fit1,
                   train_feat = data.frame(merge_m1_feat), 
                   train_labels = merge_m1_lab,
                   folds= 10,
                   loss = classification_error,
                   fit_type='class')


#BLOCK VALIDATION
qda.fit2 = qda(label ~ ., data = merge_m2)

# CV 
cv.qda2 = CVmaster(classifier = qda.fit2,
                   train_feat = data.frame(merge_m2_feat), 
                   train_labels = merge_m2_lab,
                   folds= 10,
                   loss = classification_error,
                   fit_type='class')

custom_merge(cv.qda1, cv.qda2)
```

### TEST QDA

```{r}
# method 1 
test_qda_label1 = predict(qda.fit1, naive_test[,c(4,5,6)], 
                          type = "response")$class
qda_error_1 = 1 - mean(test_qda_label1 == naive_test$label)

# method 2 
test_qda_label2 = predict(qda.fit2, alt_test[,c(4,5,6)], 
                          type = "response")$class
qda_error_2 = 1 - mean(test_qda_label2 == alt_test$label)

cat("method 1: ", qda_error_1, "\n", "method 2: ", qda_error_2)
```

XGBOOST

```{r}

# specific for xgb labels, can only be 0 / 1
merge_m1_xg = merge_m1_lab |>
  mutate(label = ifelse(label==-1,0,1))

merge_m2_xg = merge_m2_lab |>
  mutate(label = ifelse(label==-1,0,1))

# training 
# NAIVE 
dtrain1 <- xgb.DMatrix(data = as.matrix(merge_m1_feat),
                      label = as.matrix(merge_m1_xg))
xgboost1 <- xgboost(data = dtrain1, 
                      max.depth = 2, eta = 1, 
                      nthread = 2, nrounds = 2, 
                      objective = "binary:logistic")
# CV 
cv.xgboost1 = CVmaster(classifier = xgboost1,
                   train_feat = as.matrix(merge_m1_feat), 
                   train_labels = merge_m1_lab,
                   folds= 10,
                   loss = classification_error,
                   fit_type='response')

# BLOCK METHOD 
dtrain2 <- xgb.DMatrix(data = as.matrix(merge_m2_feat),
                      label = as.matrix(merge_m2_xg))
xgboost2 <- xgboost(data = dtrain2, 
                      max.depth = 2, eta = 1, 
                      nthread = 2, nrounds = 2, 
                      objective = "binary:logistic")
# CV 
cv.xgboost2 = CVmaster(classifier = xgboost2,
                   train_feat = as.matrix(merge_m2_feat), 
                   train_labels = merge_m2_lab,
                   folds= 10,
                   loss = classification_error,
                   fit_type='response')

custom_merge(cv.xgboost1,cv.xgboost2)
```

### TEST XGBOOST

```{r}

# method 1 
xg_test_1 = predict(xgboost1, as.matrix(naive_test[,c(4,5,6)]))

xg_lab1 = rep(-1, length(xg_test_1))
xg_lab1[xg_test_1 > 0.5] = 1

naive_err_xg1 = 1 - mean(xg_lab1 == naive_test$label)

# method 2
xg_test_2 = predict(xgboost2, as.matrix(alt_test[,c(4,5,6)]))

xg_lab2 = rep(-1, length(xg_test_2))
xg_lab2[xg_test_2 > 0.5] = 1

err_xg2 = 1 - mean(xg_lab2 == alt_test$label)

cat("method 1: ", naive_err_xg1, "\n", "method 2: ", err_xg2)
```

## b) ROC curves

QDA

```{r}
test_prob1 = predict(qda.fit1, naive_test[,c(4,5,6)], 
                          type = "response")$posterior[,2]
test_roc1 = roc(naive_test$label ~ test_prob1, plot = TRUE, print.auc = TRUE)


test_prob2 =  predict(qda.fit2, alt_test[,c(4,5,6)], 
                          type = "response")$posterior[,2]
test_roc2 = roc(alt_test$label ~ test_prob2, plot = TRUE, print.auc = TRUE)
```

XGBOOST

```{r}
XGBOOSTtest_roc1 = roc(naive_test$label ~ xg_test_1, plot = TRUE, print.auc = TRUE)

XGBOOSTtest_roc2 = roc(alt_test$label ~ xg_test_2, plot = TRUE, print.auc = TRUE)
```

## c) (bonus) other metrics

# 4) Diagnostics

question: is there 0 labels in our test data? should we filter those out? how does cbind work if so? man...

```{r}
#QDA
p1qda = cbind(naive_test, test_qda_label1)
p2qda = cbind(alt_test, test_qda_label2)

#XGBOOST
p1xgboost = cbind(naive_test, xg_lab1)
p2xgboost = cbind(alt_test, xg_lab2)
```

QDA: NAIVE WAY PLOT COMPARISON

```{r}
p1 = ggplot(p1qda %>% filter(label != 0), aes(x=x,y=y)) + 
  geom_point(aes(colour = factor(label))) + 
  facet_grid(cols = vars(source)) + 
  #labs(title = "Images With Expert Labels",
  #     subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  scale_colour_brewer("Expert \nLabel") + 
  theme_bw()

p2 = ggplot(p1qda %>% filter(label != 0), aes(x=x,y=y)) + 
  geom_point(aes(colour = test_qda_label1)) + 
  facet_grid(cols = vars(source)) + 
  #labs(title = "Images With Predicted Labels",
  #     subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  scale_colour_brewer("Predicted \nLabel") + 
  theme_bw()

p1 + p2
```

QDA: ALTERNATIVE WAY

```{r}
p3 = ggplot(p2qda %>% filter(label != 0), aes(x=x,y=y)) + 
  geom_point(aes(colour = factor(label))) + 
  facet_grid(cols = vars(source)) + 
  #labs(title = "Images With Expert Labels",
  #     subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  scale_colour_brewer("Expert \nLabel") + 
  theme_bw()

p4 = ggplot(p2qda %>% filter(label != 0), aes(x=x,y=y)) + 
  geom_point(aes(colour = test_qda_label2)) + 
  facet_grid(cols = vars(source)) + 
  #labs(title = "Images With Predicted Labels",
  #     subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  scale_colour_brewer("Predicted \nLabel") + 
  theme_bw()

p3 / p4
```

XGBOOST: NAIVE

```{r}
p5 = ggplot(p1xgboost %>% filter(label != 0), aes(x=x,y=y)) + 
  geom_point(aes(colour = factor(label))) + 
  facet_grid(cols = vars(source)) + 
  #labs(title = "Images With Expert Labels",
  #     subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  scale_colour_brewer("Expert \nLabel") + 
  theme_bw()

p6 = ggplot(p1xgboost %>% filter(label != 0), aes(x=x,y=y)) + 
  geom_point(aes(colour = factor(xg_lab1))) + 
  facet_grid(cols = vars(source)) + 
  #labs(title = "Images With Predicted Labels",
  #     subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  scale_colour_brewer("Predicted \nLabel") + 
  theme_bw()

p5 + p6
```

XGBOOST ALTERNATIVE

```{r}
p7 = ggplot(p2xgboost %>% filter(label != 0), aes(x=x,y=y)) + 
  geom_point(aes(colour = factor(label))) + 
  facet_grid(cols = vars(source)) + 
  #labs(title = "Images With Expert Labels",
  #     subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  scale_colour_brewer("Expert \nLabel") + 
  theme_bw()

p8 = ggplot(p2xgboost %>% filter(label != 0), aes(x=x,y=y)) + 
  geom_point(aes(colour = factor(xg_lab2))) + 
  facet_grid(cols = vars(source)) + 
  #labs(title = "Images With Predicted Labels",
  #     subtitle = "-1: No Cloud | 0 : Uncertain | 1 : Cloud") + 
  scale_colour_brewer("Predicted \nLabel") + 
  theme_bw()

p7 / p8
```
